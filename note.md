* [X] Get test subsets
* [ ] Save index of subsets
* [ ] make a expriments for all subsets to run multiple times.
* [ ] Pick all the txt files and summerize the results



* [ ] Use two subjects and build a model & test --> performace
* [ ] Tool development


* [ ] Think deeper about a ramdom original size as input. What will the subsets look like?
  * [ ] A function to calculate how many times a subset should run COMMIT
  * [ ] Data structure of the input and output




raw data -> size 

10mio  5

5mio 10

2.5mio 20

1.25mio 40

625k 80

500k 100

250k 200

---



10mio  5   ï¼ˆ5h)

5mio 10

500k 100  

250k 200

---

Raw data --> give sizes of
